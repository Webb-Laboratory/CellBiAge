{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning -- before count binarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "The **MLAging** workflow consists of four sections:\n",
    "\n",
    "I. Data Preprocessing in Seurat ```preprocessing.R```\n",
    "\n",
    "II. Model Tunning (hyperparameter selection for  with ```GridSearchCV```) -- **this notebook: same as *Model Tuning* notebook except for the count matrix binarization**:\n",
    "\n",
    "1. [Data Preparation](#1.-prep)\n",
    "2. [Model Tunning](#2.-tunning)\n",
    "    - [Lasso](#3.-l1)\n",
    "    - [Ridge](#4.-l2)\n",
    "    - [ElasticNet](#5.-eln)\n",
    "    \n",
    "    - [Random Forest](#6.-rfc)\n",
    "    - [XGBoost](#7.-xgbc)\n",
    "    \n",
    "    - [Support Vector Machine with rbf kernel](#8.-svc)\n",
    "\n",
    "III. Model Comparison\n",
    "\n",
    "IV. Final Model Over 10 Random States\n",
    "\n",
    "V. Results and Intepretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src.data_processing import *\n",
    "from src.grid_search import *\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "data_type = 'float32'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation <a name=\"1.-prep\"></a>\n",
    "### Load training, testing batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test = '../data/test_final_group_info.csv'\n",
    "input_train = '../data/train_final_group_info.csv'\n",
    "\n",
    "cell_type = 'All'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y, custom_cv = data_prep(input_test, input_train,\n",
    "                                                        cell_type, binarization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_auc_scorer = make_scorer(pr_auc_score, greater_is_better=True,\n",
    "                            needs_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model tunning<a name=\"2.-tunning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Logistic regression -- l1<a name=\"3.-l1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l1 = LogisticRegression(penalty='l1', solver='saga', max_iter=10000000)\n",
    "# 0.01, 0.05, 0.1, 0.5, 1, 5, 8, 10, 20, 50, 100 \n",
    "# 12.5, 15, 17.5, 20, 25, 30, 35, 40\n",
    "param_grid = {'logisticregression__C': np.logspace(-3, 2, 10)}\n",
    "\n",
    "models_l1 = []\n",
    "for i in tqdm(range(10)):\n",
    "    grid, test_score = ML_pipeline_GridSearchCV(train_X, train_y, test_X, test_y, \n",
    "                                                l1, param_grid, i, custom_cv, pr_auc_scorer)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:', grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    models_l1.append(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../results/all_cells_before/l1_models_10.save', 'wb')\n",
    "pickle.dump(models_l1, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Logistic regression -- l2<a name=\"4.-l2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = LogisticRegression(penalty='l2', solver='saga', max_iter=10000000)\n",
    "param_grid = {'logisticregression__C': np.logspace(-3, 2, 10)}\n",
    "\n",
    "models_l2 = []\n",
    "for i in tqdm(range(10)):\n",
    "    grid, test_score = ML_pipeline_GridSearchCV(train_X, train_y, test_X, test_y, l2, param_grid, i)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:', grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    models_l2.append(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../results/all_cells_before/l2_models_10.save', 'wb')\n",
    "pickle.dump(models_l2, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.logspace(-3, 2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Logistic regression -- ElasticNet<a name=\"5.-eln\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eln = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=10000000)\n",
    "param_grid = {'logisticregression__C':  np.logspace(-3, 2, 10),\n",
    "             'logisticregression__l1_ratio': [0.05, 0.1, 0.2, 0.35]}\n",
    "\n",
    "models_eln = []\n",
    "for i in tqdm(range(10)):\n",
    "    grid, test_score = ML_pipeline_GridSearchCV(train_X, train_y, test_X, test_y, \n",
    "                                                eln, param_grid, i, custom_cv, pr_auc_scorer)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:', grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    models_eln.append(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../results/all_cells_before/eln_models_10_finer.save', 'wb')\n",
    "pickle.dump(models_eln, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Random Forest Classifier<a name=\"6.-rfc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "param_grid = {'randomforestclassifier__max_features': [10, 15, 20, 25, 50, None],\n",
    "              'randomforestclassifier__max_depth': [10, 20, 30, 50, 100, None],\n",
    "              'randomforestclassifier__min_samples_split': [2, 5, 10, 20]}\n",
    "\n",
    "models_rfc = []\n",
    "for i in tqdm(range(10)):\n",
    "    grid, test_score = ML_pipeline_GridSearchCV(train_X, train_y, test_X, test_y, rfc, param_grid, i)\n",
    "\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:', grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    models_rfc.append(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../results/all_cells/rfc_models_10.save', 'wb')\n",
    "pickle.dump(models_rfc, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) XGBoost Classifier<a name=\"#7.-xgbc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgbc = XGBClassifier(use_label_encoder=False)\n",
    "param_grid = {'xgbclassifier__max_depth': [1, 3, 5, 10, 20, 30, 100],\n",
    "              \"xgbclassifier__learning_rate\": [0.03],\n",
    "              #'xgbclassifier__min_child_weight': [1, 3, 5, 7],\n",
    "              #'xgbclassifier__gamma': [0, 0.1, 0.2 , 0.3, 0.4],\n",
    "              'xgbclassifier__colsample_bytree': [0.9],\n",
    "              'xgbclassifier__subsample': [0.66],\n",
    "              'xgbclassifier__eval_metric': ['logloss']}\n",
    "\n",
    "models_xgbc = []\n",
    "for i in tqdm(range(10)):\n",
    "    grid, test_score = ML_pipeline_GridSearchCV(train_X, train_y, test_X, test_y, xgbc, param_grid, i, xgbc=True)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:', grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    models_xgbc.append(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../results/all_cells_before/xgbc_models_10.save', 'wb')\n",
    "pickle.dump(models_xgbc, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) SVC<a name=\"8.-svc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(probability=True)\n",
    "# 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1\n",
    "param_grid = {'svc__gamma': np.logspace(-3, 2, 6),\n",
    "              'svc__C': np.logspace(-3, 2, 6)}\n",
    "\n",
    "models_svc = []\n",
    "for i in tqdm(range(10)):\n",
    "    grid, test_score = ML_pipeline_GridSearchCV(train_X, train_y, test_X, test_y, svc, param_grid, i)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:', grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    models_svc.append(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../results/all_cells_before/svc_models_10.save', 'wb')\n",
    "pickle.dump(models_svc, file)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellpymc",
   "language": "python",
   "name": "cellpymc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
