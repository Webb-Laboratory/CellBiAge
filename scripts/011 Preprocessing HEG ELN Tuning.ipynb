{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELN tuning for different preprocessing methods - HEGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "The **MLAging - preprocessing** workflow consists of sections:\n",
    "\n",
    "`00 preprocessing.R` Data preprocessing and preparation in Seurat.\n",
    "\n",
    "`011 Preprocessing HEG ELN Tuning` ELN model tunning using highly expressed genes (HEGs) and hyperparameter selection using `GridSearchCV` -- **this notebook**:\n",
    "\n",
    "#### [HEG ELN Model Tuning](#1.-HEG)\n",
    "- [HEG-lognorm](#2.-heg_lognorm)\n",
    "- [HEG-std](#3.-heg_std)\n",
    "- [HEG-integration](#4.-heg_integrated)\n",
    "- [HEG-binarization](#5.-heg_bin)\n",
    "    \n",
    "`012 Preprocessing HVG ELN Tuning` ELN model tunning using highly variable genes (HVGs) and hyperparameter selection using `GridSearchCV`.\n",
    "\n",
    "`02 Preprocessing ELN Result 10x` Run the best ELN model over 10 random seeds.\n",
    "\n",
    "`03 Preprocessing ELN Result Viz` Result visulization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src.data_processing import *\n",
    "from src.grid_search import *\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "data_type = 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_target(input_df):\n",
    "    input_df = pd.read_csv(input_df, index_col=0)\n",
    "    input_df['animal'] = input_df.index.str[-1]\n",
    "    input_df['target'] = ((input_df['animal'] =='3')|(input_df['animal']=='4')).astype(int)\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(input_train, input_test, binarization=False):\n",
    "    \n",
    "    df_test = assign_target(input_test)\n",
    "    test_X = df_test.iloc[:,:-2]\n",
    "    test_y = df_test.target\n",
    "    test_X, test_y = shuffle(test_X, test_y, random_state=42)\n",
    "\n",
    "    df_train = assign_target(input_train)\n",
    "    train = df_train.reset_index()\n",
    "    custom_cv = customized_cv_index(train)\n",
    "    \n",
    "    train_X = train.iloc[:,1:-2]\n",
    "    train_y = train.target\n",
    "    \n",
    "    if binarization==True:\n",
    "        test_X = binarize_data(test_X)\n",
    "        train_X = binarize_data(train_X)\n",
    "    \n",
    "    return train_X, train_y, test_X, test_y, custom_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_auc_scorer = make_scorer(pr_auc_score, greater_is_better=True,\n",
    "                            needs_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELN model tuning for the top2k HEGs <a name=\"1.-HEG\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) HEG - log-normalized <a name=\"2.-heg_lognorm\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = '../data/train_heg2k_lognorm_intersect.csv'\n",
    "input_test = '../data/test_heg2k_lognorm_intersect.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y, custom_cv = train_test_split(input_train, input_test, binarization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [2:42:06<5:24:13, 9726.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.01, 'logisticregression__l1_ratio': 1.0}\n",
      "best CV score: 0.690676182858998\n",
      "test score: 0.6712988646865272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 2/3 [6:39:27<3:26:21, 12381.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.01, 'logisticregression__l1_ratio': 1.0}\n",
      "best CV score: 0.6906209515897587\n",
      "test score: 0.6712998613287319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [10:42:11<00:00, 12843.90s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.01, 'logisticregression__l1_ratio': 1.0}\n",
      "best CV score: 0.6906515079431652\n",
      "test score: 0.6712992375756468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eln = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=10000000)\n",
    "# the other hps tested\n",
    "# param_grid = {'logisticregression__C': np.logspace(-4, 4, 10),\n",
    "#              'logisticregression__l1_ratio': np.logspace(-3, 0, 5)}\n",
    "# [0.05, 0.1, 0.2, 0.35]\n",
    "\n",
    "param_grid = {'logisticregression__C': np.logspace(-2, 2, 10),\n",
    "             'logisticregression__l1_ratio': np.logspace(-3, 0, 6)}\n",
    "models_eln = []\n",
    "for i in tqdm(range(3)):\n",
    "    grid, test_score = ML_pipeline_GridSearchCV(train_X, train_y, test_X, test_y, \n",
    "                                                eln, param_grid, i, custom_cv, pr_auc_scorer)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:', grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    models_eln.append(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) HEG - log-normalized + scaled<a name=\"3.-heg_std\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = '../data/train_heg2k_std_intersect.csv'\n",
    "input_test = '../data/test_heg2k_std_intersect.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y, custom_cv = train_test_split(input_train, input_test, binarization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [1:15:48<2:31:37, 4548.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.01, 'logisticregression__l1_ratio': 1.0}\n",
      "best CV score: 0.6703216336692734\n",
      "test score: 0.6728107688645167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 2/3 [2:31:42<1:15:51, 4551.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.01, 'logisticregression__l1_ratio': 1.0}\n",
      "best CV score: 0.6703241709145165\n",
      "test score: 0.6728116909753354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [3:47:33<00:00, 4551.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.01, 'logisticregression__l1_ratio': 1.0}\n",
      "best CV score: 0.6703240555084935\n",
      "test score: 0.6728204947208725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eln = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=10000000)\n",
    "# param_grid = {'logisticregression__C': np.logspace(-4, 4, 10),\n",
    "#              'logisticregression__l1_ratio': np.logspace(-3, 0, 5)}\n",
    "param_grid = {'logisticregression__C': np.logspace(-2, 2, 10),\n",
    "             'logisticregression__l1_ratio': np.logspace(-3, 0, 6)}\n",
    "# [0.05, 0.1, 0.2, 0.35]\n",
    "models_eln = []\n",
    "for i in tqdm(range(3)):\n",
    "    grid, test_score = ML_pipeline_GridSearchCV(train_X, train_y, test_X, test_y, \n",
    "                                                eln, param_grid, i, custom_cv, pr_auc_scorer)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:', grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    models_eln.append(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) HEG - log-normalized + scaled + integrated <a name=\"4.-heg_integrated\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = '../data/train_heg2k_std_integrated.csv'\n",
    "input_test = '../data/test_heg2k_std_integrated.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y, custom_cv = train_test_split(input_train, input_test, binarization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [05:36<11:12, 336.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.01, 'logisticregression__l1_ratio': 1.0}\n",
      "best CV score: 0.5265876990684155\n",
      "test score: 0.6888078006294425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 2/3 [11:13<05:36, 336.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.01, 'logisticregression__l1_ratio': 1.0}\n",
      "best CV score: 0.5265869236657875\n",
      "test score: 0.6888062319276776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [16:43<00:00, 334.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.01, 'logisticregression__l1_ratio': 1.0}\n",
      "best CV score: 0.5265870582412444\n",
      "test score: 0.6888062161805402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eln = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=10000000)\n",
    "# param_grid = {'logisticregression__C': np.logspace(-4, 4, 10),\n",
    "#              'logisticregression__l1_ratio': np.logspace(-3, 0, 5)}\n",
    "param_grid = {'logisticregression__C': np.logspace(-2, 2, 10),\n",
    "             'logisticregression__l1_ratio': np.logspace(-3, 0, 6)}\n",
    "# [0.05, 0.1, 0.2, 0.35]\n",
    "models_eln = []\n",
    "for i in tqdm(range(3)):\n",
    "    grid, test_score = ML_pipeline_GridSearchCV(train_X, train_y, test_X, test_y, \n",
    "                                                eln, param_grid, i, custom_cv, pr_auc_scorer)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:', grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    models_eln.append(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) HEG - log-normalized + scaled + integrated + binarized <a name=\"5.-heg_bin\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y, custom_cv = train_test_split(input_train, input_test, binarization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [12:58<25:56, 778.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.01, 'logisticregression__l1_ratio': 1.0}\n",
      "best CV score: 0.5202947064158397\n",
      "test score: 0.607951176367699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 2/3 [26:01<13:01, 781.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.01, 'logisticregression__l1_ratio': 1.0}\n",
      "best CV score: 0.5202909914637522\n",
      "test score: 0.6079509180657812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [39:03<00:00, 781.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.01, 'logisticregression__l1_ratio': 1.0}\n",
      "best CV score: 0.520293493011841\n",
      "test score: 0.6079511119121208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eln = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=10000000)\n",
    "# param_grid = {'logisticregression__C': np.logspace(-4, 4, 10),\n",
    "#              'logisticregression__l1_ratio': np.logspace(-3, 0, 5)}\n",
    "param_grid = {'logisticregression__C': np.logspace(-2, 2, 10),\n",
    "             'logisticregression__l1_ratio': np.logspace(-3, 0, 6)}\n",
    "# [0.05, 0.1, 0.2, 0.35]\n",
    "models_eln = []\n",
    "for i in tqdm(range(3)):\n",
    "    grid, test_score = ML_pipeline_GridSearchCV(train_X, train_y, test_X, test_y, \n",
    "                                                eln, param_grid, i, custom_cv, pr_auc_scorer)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:', grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    models_eln.append(grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellpymc",
   "language": "python",
   "name": "cellpymc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
